# Pulse Stack - Plateforme de DonnÃ©es Moderne

Une plateforme de donnÃ©es complÃ¨te utilisant une architecture moderne avec orchestration, ingestion, transformation et visualisation.

## ğŸ—ï¸ Architecture

![Architecture Pulse Stack](architecture.png)

## ğŸš€ Services Inclus

### ğŸ“Š **PostgreSQL** - Base de donnÃ©es principale
- **Port:** 5433 (externe) / 5432 (interne)
- **Utilisateur:** admin / admin
- **Bases:** healthcare, airflow, superset, airbyte
- **Stockage:** DonnÃ©es Silver/Gold (nettoyÃ©es et agrÃ©gÃ©es)

### ğŸª£ **MinIO** - Stockage objet (Data Lake)
- **Console:** http://localhost:9001
- **API:** http://localhost:9000
- **Utilisateur:** minio / minio123
- **Buckets:** bronze (donnÃ©es brutes uniquement)
- **Formats:** Parquet, JSON, CSV

### ğŸ”„ **Airbyte** - Ingestion de donnÃ©es
- **Interface:** http://localhost:8000
- **Utilisateur:** airbyte / password
- Connecteurs pour diverses sources de donnÃ©es
- Synchronisation batch et temps rÃ©el
- Destination : MinIO (Bronze layer)

### ğŸŒªï¸ **Airflow** - Orchestration
- **Interface:** http://localhost:8080
- **Utilisateur:** admin / admin
- Orchestration des pipelines ETL/ELT
- Monitoring et alertes
- DÃ©clenche les transformations dbt

### ğŸ”§ **dbt** - Transformation des donnÃ©es
- Architecture Medallion (Bronze â†’ Silver â†’ Gold)
- Source : MinIO (Bronze) â†’ Destination : PostgreSQL (Silver/Gold)
- Tests de qualitÃ© intÃ©grÃ©s
- Documentation automatique

### âœ… **Great Expectations** - Validation qualitÃ©
- Validation des donnÃ©es automatisÃ©e
- Profiling des schÃ©mas PostgreSQL
- Rapports de qualitÃ© des donnÃ©es
- IntÃ©gration avec dbt

### ğŸ“ˆ **Superset** - Visualisation BI
- **Interface:** http://localhost:8088
- **Utilisateur:** admin / admin
- Dashboards interactifs
- Source de donnÃ©es : PostgreSQL (Silver/Gold)
- Exploration de donnÃ©es business-ready

### ğŸ”´ **Redis** - Cache et file d'attente
- **Port:** 6379 (interne uniquement)
- Cache pour Airflow et autres services
- File d'attente pour les tÃ¢ches asynchrones
// ...existing code...

## ğŸƒâ€â™‚ï¸ DÃ©marrage Rapide

### PrÃ©requis
- Docker et Docker Compose installÃ©s
- Au moins 8GB de RAM disponible
- Ports 5432, 8000, 8080, 8088, 9000, 9001 libres

### 1. DÃ©marrage automatique
```bash
./start-platform.sh up
```

### 2. DÃ©marrage manuel
```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier l'Ã©tat
docker-compose ps

# Voir les logs
docker-compose logs -f [service-name]
```

### 3. ArrÃªt
```bash
# ArrÃªter les services
docker-compose down

# Nettoyer complÃ¨tement (âš ï¸ supprime les donnÃ©es)
docker-compose down -v
```

## ğŸ“‹ AccÃ¨s aux Services

| Service | URL | Utilisateur | Mot de passe |
|---------|-----|-------------|--------------|
| Airflow | http://localhost:8080 | admin | admin |
| Airbyte | http://localhost:8000 | - | - |
| Superset | http://localhost:8088 | admin | admin |
| MinIO Console | http://localhost:9001 | minio | minio123 |
| PostgreSQL | localhost:5432 | admin | admin |

## ğŸ”§ Configuration

### Airflow
- DAGs: `./airflow/dags/`
- Logs: `./airflow/logs/`
- Plugins: `./airflow/plugins/`

### dbt
- Models: `./dbt/models/`
- Profils: `./dbt/profiles.yml`
- Configuration: `./dbt/dbt_project.yml`

### Superset
- Configuration: `./superset/superset_config.py`
- DonnÃ©es: `./superset/`

### Great Expectations
- Configuration: `./great_expectations/`

## ğŸ“Š Architecture Medallion

### ğŸ¥‰ Bronze Layer (DonnÃ©es Brutes)
- Stockage: MinIO bucket `bronze`
- Format: Parquet, JSON, CSV
- RÃ©tention: DonnÃ©es brutes non transformÃ©es

### ğŸ¥ˆ Silver Layer (DonnÃ©es NettoyÃ©es)
- Stockage: MinIO bucket `silver` + PostgreSQL
- Transformations: Nettoyage, dÃ©duplication, typage
- Tests: Validations de qualitÃ© de base

### ğŸ¥‡ Gold Layer (DonnÃ©es Business)
- Stockage: MinIO bucket `gold` + PostgreSQL
- AgrÃ©gations: MÃ©triques business, KPIs
- Optimisation: Tables dÃ©normalisÃ©es pour analytics

## ğŸ” Monitoring et Maintenance

### Health Checks
```bash
# VÃ©rifier tous les services
./start-platform.sh

# VÃ©rifier un service spÃ©cifique
docker-compose exec [service] health_check
```

### Logs
```bash
# Logs en temps rÃ©el
docker-compose logs -f

# Logs d'un service
docker-compose logs -f airflow-webserver
```

### MÃ©triques
- Airflow: Interface web avec mÃ©triques DAG
- PostgreSQL: pg_stat_activity pour monitoring
- MinIO: MÃ©triques dans l'interface console

## ğŸ› ï¸ DÃ©veloppement

### Ajouter un DAG Airflow
1. CrÃ©er le fichier dans `./airflow/dags/`
2. Le DAG sera automatiquement dÃ©tectÃ©
3. VÃ©rifier dans l'interface Airflow

### Ajouter un modÃ¨le dbt
1. CrÃ©er le fichier SQL dans `./dbt/models/`
2. ExÃ©cuter: `docker-compose exec dbt dbt run`
3. Tests: `docker-compose exec dbt dbt test`

### Configurer une source Airbyte
1. Interface: http://localhost:8000
2. CrÃ©er Source â†’ Destination
3. Configurer la synchronisation

## ğŸ”’ SÃ©curitÃ©

âš ï¸ **Configuration de dÃ©veloppement uniquement!**

Pour la production:
- Changer tous les mots de passe par dÃ©faut
- Utiliser des secrets externes (Vault, etc.)
- Configurer HTTPS/TLS
- Mise en place de l'authentification SSO
- Network policies restrictives

## ğŸ“š Ressources

- [Documentation Airflow](https://airflow.apache.org/docs/)
- [Documentation dbt](https://docs.getdbt.com/)
- [Documentation Airbyte](https://docs.airbyte.com/)
- [Documentation Superset](https://superset.apache.org/docs/)
- [Documentation Great Expectations](https://docs.greatexpectations.io/)

## ğŸ¤ Support

Pour des questions ou problÃ¨mes:
1. VÃ©rifier les logs: `docker-compose logs [service]`
2. RedÃ©marrer le service: `docker-compose restart [service]`
3. Consulter la documentation du service concernÃ©
